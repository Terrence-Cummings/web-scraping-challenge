{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Homework - Mission to Mars\n",
    "## Terrence Cummings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import requests\n",
    "import pymongo\n",
    "from splinter import Browser\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Scraping\n",
    "## NASA Mars New\n",
    "\n",
    "Retrieve the following data from a search of the latest news articles at the NASA Mars News website URL:\n",
    "\n",
    "1. Publication Date\n",
    "\n",
    "2. Title\n",
    "\n",
    "3. Summary paragraph\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "#Because the search results at the URL are from Javascript use Selenium to scrape the data\n",
    "\n",
    "#URL for NASA Mars News website. This show 40 articles from a search of the criteria \"Latest\" and \"All Categories\".\n",
    "#Results of the search are generated by Javascript so not viewable in the webpage HTML\n",
    "url_mars_news = 'https://mars.nasa.gov/news/?page=0&per_page=40&order=publish_date+desc%2Ccreated_at+desc&search=&category=19%2C165%2C184%2C204&blank_scope=Latest'\n",
    "\n",
    "#Initialize lists to store Selenium objects\n",
    "dates = []\n",
    "titles = []\n",
    "summarys = []\n",
    "\n",
    "#Use Selenium to get the needed fields from the JS results\n",
    "#XPath for tags were found by right-clicking on the tag in the Chrome Inspector tool the Copy XPath\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(url_mars_news)\n",
    "\n",
    "#Add a delay to give the scraper time to acquire the data\n",
    "time.sleep(10)\n",
    "dates = driver.find_elements_by_xpath('//*[@id=\"page\"]/div[3]/div/article/div/section/div/ul/li[*]/div/div/div[1]')\n",
    "titles = driver.find_elements_by_xpath('//*[@id=\"page\"]/div[3]/div/article/div/section/div/ul/li[*]/div/div/div[2]/a')\n",
    "summarys = driver.find_elements_by_xpath('//*[@id=\"page\"]/div[3]/div/article/div/section/div/ul/li[*]/div/div/div[3]')\n",
    "\n",
    "# create empty array to store text data extracted from Selenium objects\n",
    "date_lst = []\n",
    "title_lst = []\n",
    "summary_lst = []\n",
    "\n",
    "# loop over results and extract text from Selenium objects, add to each list\n",
    "for date in dates:\n",
    "    article_date = date.text\n",
    "    date_lst.append(article_date)\n",
    "for title in titles:\n",
    "    article_title = title.text\n",
    "    title_lst.append(article_title)\n",
    "for summary in summarys:\n",
    "    article_summary = summary.text\n",
    "    summary_lst.append(article_summary)\n",
    "\n",
    "#Make dataframe of NASA Mars Latest News Articles\n",
    "nasa_mars_articles_df = pd.DataFrame(list(zip(date_lst, title_lst, summary_lst)), columns =['Date', 'Title', 'Summary'])\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confirm results of the scraping\n",
    "nasa_mars_articles_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JPL Mars Space Images - Featured Images\n",
    "Get the URL for the featured image at the website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "#Setup Splinter Browsder and target URL\n",
    "executable_path = {'executable_path': '/usr/local/bin/chromedriver'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)\n",
    "url_jpl = 'https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars'\n",
    "\n",
    "#Go to URL and navigate to page with full size image.\n",
    "browser.visit(url_jpl)\n",
    "browser.click_link_by_partial_text('FULL IMAGE')\n",
    "browser.click_link_by_partial_text('more info')\n",
    "\n",
    "#Grab the HTM from the webpage with the full size image which contains the link to that image\n",
    "html = browser.html\n",
    "browser.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use BeautifulSoup to parse the HTML\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "#Find the image tag for the main image\n",
    "main_img = soup.find('img', class_='main_image')\n",
    "\n",
    "#Extract the source link for the image\n",
    "main_img_url = main_img['src']\n",
    "\n",
    "#Build the full URL to the full size featured image\n",
    "main_img_url_full = 'https://www.jpl.nasa.gov'+main_img_url\n",
    "\n",
    "#Check result\n",
    "main_img_url_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mars Weather\n",
    "Get the latest Mars Weather tweet from Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use Selenium because Twitter tweets are populated by JS\n",
    "url_mars_tweet = 'https://twitter.com/marswxreport?lang=en'\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(url_mars_tweet)\n",
    "time.sleep(1)\n",
    "\n",
    "#Get the first Mars weather tweet using Xpath in Selenium\n",
    "mars_weather_tweet_obj = driver.find_elements_by_xpath('//*[@id=\"react-root\"]/div/div/div[2]/main/div/div/div/div[1]/div/div/div/div/div[2]/section/div/div/div/div[1]/div/div/div/div/article/div/div[2]/div[2]/div[2]/div[1]/div/span')\n",
    "\n",
    "#Extract the text of the tweet and replace line breaks\n",
    "mars_weather_tweet = mars_weather_tweet_obj[0].text.replace('\\n',', ')\n",
    "\n",
    "#Close browser\n",
    "driver.quit()\n",
    "\n",
    "#Check result\n",
    "mars_weather_tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mars Facts\n",
    "Get table of Mars facts using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Send Pandas to read tables from URL\n",
    "mars_facts_url = 'https://space-facts.com/mars/'\n",
    "mars_facts = pd.read_html(mars_facts_url)\n",
    "\n",
    "#Grab the first table of facts, add column headings\n",
    "mars_facts_df = mars_facts[0]\n",
    "mars_facts_df.columns = ['Parameter', 'Fact']\n",
    "\n",
    "#Write as HTML table\n",
    "mars_facts_df.to_html('mars_facts_table.html', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mars Hemispheres\n",
    "\n",
    "Create a list of dictionaries containing the URL's and Titles for images of Mars' hemispheres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "sys.stdout = open('output.txt','wt')\n",
    "print(soup.prettify())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python361064bitpythondatacondaab47c43dfe824d4eb95e9e8f15b48370",
   "display_name": "Python 3.6.10 64-bit ('PythonData': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}